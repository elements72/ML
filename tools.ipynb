{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful pandas snips of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data explorations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot\n",
    "\n",
    "#--Checking Outliers\n",
    "plt.figure(figsize=(20, 20))\n",
    "pos = 1\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object':\n",
    "        plt.subplot(3, 4, pos)\n",
    "        ax = sns.boxplot(df[i])\n",
    "        ax.set_title(i)\n",
    "        pos += 1\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms for categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### adjust the line below\n",
    "plt.hist(df['class'])\n",
    "# Or you can do in this way\n",
    "#df[\"class\"].value_counts().plot(title=\"class\", kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# Remove features with low variance\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8))).set_output(transform='pandas')\n",
    "df_variance = sel.fit_transform(df)\n",
    "df_variance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 2 features based on mutual info regression\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "selector = SelectKBest(mutual_info_regression, k=2).set_output(transform='pandas')\n",
    "df_kbest = selector.fit_transform(X, y)\n",
    "df_kbest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove highly correlated features\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrx = df.corr()\n",
    "\n",
    "corr_threshold = 0.95\n",
    "upper = corr_matrx.where(\n",
    "np.triu(np.ones(corr_matrx.shape), k=1).astype(bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > corr_threshold)]\n",
    "print(to_drop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1  # Interquartile range\n",
    "    fence_low = q1-1.5*iqr\n",
    "    fence_high = q3+1.5*iqr\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) &\n",
    "                       (df_in[col_name] < fence_high)]\n",
    "    return df_out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful import\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "grid = {\n",
    "    'max_depth': [4, 5, 6, 7, 8, 10, 14],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=grid)\n",
    "cv = cv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVM\n",
    "# N.B. very slow\n",
    "grid_svc = [{'kernel': ['rbf'],\n",
    "                    'gamma': [1e-3, 1e-4],\n",
    "                    'C': [1, 10, 100, 1000],\n",
    "                    },\n",
    "                   {'kernel': ['linear'],\n",
    "                    'C': [1, 10, 100, 1000],\n",
    "                    },\n",
    "                   ]\n",
    "\n",
    "\n",
    "cv = GridSearchCV(estimator=SVC(), param_grid=grid_svc)\n",
    "cv = cv.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn = [{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]\n",
    "\n",
    "\n",
    "cv = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=grid_knn)\n",
    "cv = cv.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix with values\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred, labels=df.language.unique()),\n",
    "            annot=True, xticklabels=df.language.unique(), yticklabels=df.language.unique(), fmt='g')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "n_cluster_range = range(2,10)\n",
    "distortions = []\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clust in n_cluster_range:\n",
    "\n",
    "    km = KMeans(n_clusters = n_clust)\n",
    "    \n",
    "    \n",
    "    y_km = km.fit_predict(X)\n",
    "    distortion = km.inertia_\n",
    "    silhouette = silhouette_score(X,y_km)\n",
    "    \n",
    "    distortions.append(distortion)\n",
    "    silhouette_scores.append(silhouette)\n",
    "    \n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Number of clusters')\n",
    "ax1.set_ylabel('Inertia', color=color)\n",
    "ax1.plot(n_cluster_range, distortions, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  \n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Silhouette scores', color=color)  \n",
    "ax2.plot(n_cluster_range, silhouette_scores, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.set_ylim(0,1) \n",
    "\n",
    "fig.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_k = #k chosen before via elbow method\n",
    "km = KMeans(n_clusters=good_k, \n",
    "            init='k-means++', \n",
    "            n_init=10, \n",
    "            max_iter=300,\n",
    "            tol=1e-04,\n",
    "            )\n",
    "y_km = km.fit_predict(X)\n",
    "\n",
    "#Silhouette score of the best parameter choice\n",
    "print(silhouette_score(X,y_km))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplot after clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = X.assign(Class=y_km)\n",
    "\n",
    "sns.pairplot(data=df_test, hue=\"Class\");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset from a txt file with a line as single transaction\n",
    "transactions = []\n",
    "data = []\n",
    "\n",
    "with open(\"./online_retail_red.txt\") as f:\n",
    "    for line in f.readlines():\n",
    "        transaction = []\n",
    "        item_dic = {}\n",
    "        for item in line.split(\";\"):\n",
    "            item_dic.setdefault(item, 1)\n",
    "            transaction.append(str.strip(item))\n",
    "        transactions.append(transaction)\n",
    "        data.append(item_dic)\n",
    "# Create our transcation number\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovery of frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "min_itemsets = 8\n",
    "min_item_in_itemset = 2\n",
    "\n",
    "# \"Reasonable\" range\n",
    "support_range = np.arange(0.1, 0.01, -0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_support = 0\n",
    "\n",
    "    frequent_itemsets = None\n",
    "    itemsets_above_threshold = 0\n",
    "\n",
    "for s_value in support_range:\n",
    "\n",
    "    print(f\"Trying support value {s_value:.2f}\")\n",
    "\n",
    "    frequent_itemsets = apriori(df, min_support = s_value, use_colnames = True)\n",
    "\n",
    "    # Calculate the number of itemsets that contain at least `min_item_in_itemset` items\n",
    "    itemsets_above_threshold = sum([len(itemset) >= min_item_in_itemset for itemset in frequent_itemsets.itemsets])\n",
    "    \n",
    "    if itemsets_above_threshold >= min_itemsets:\n",
    "        min_support = s_value\n",
    "        break\n",
    "\n",
    "if min_support == 0:\n",
    "    print(\"No itemset found! Try again with a bigger range!\")\n",
    "else:\n",
    "    print(f\"I've selected min_support = {min_support:.2f}, which produced {len(frequent_itemsets)} itemsets, {itemsets_above_threshold} of which had more than {min_item_in_itemset} items\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovery of rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "min_rules = 10\n",
    "\n",
    "# \"Reasonable\" range\n",
    "confidence_range = np.arange(1, 0.01, -0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_confidence = 0\n",
    "\n",
    "for c_value in confidence_range:\n",
    "\n",
    "    rules = association_rules(\n",
    "        frequent_itemsets, metric=\"confidence\", min_threshold=c_value)\n",
    "\n",
    "    if len(rules) >= min_rules:\n",
    "        min_confidence = c_value\n",
    "        break\n",
    "\n",
    "print(\n",
    "    f'Metric: \"confidence\" - min_metric: {min_confidence:.4f} - Number of rules: {len(rules)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_rules = rules.sort_values(\n",
    "    by=['confidence', 'support'], ascending=False).reset_index(drop=True)\n",
    "sorted_rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of the sorted rules\n",
    "fig = sorted_rules.plot.scatter(x = 'confidence', y = 'support', title = 'Association Rules');\n",
    "\n",
    "# Iterate over all the rules and annotate them with their index\n",
    "for i in range(len(sorted_rules)):\n",
    "    fig.annotate(text = i, xy = (sorted_rules['confidence'][i], sorted_rules['support'][i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a string function (lab5)\n",
    "df0.loc[:, \"Description\"] = df0.loc[:, \"Description\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract row with null values\n",
    "df0[df0.isnull().any(axis=1)]\n",
    "# Extract row that as null value on just one column\n",
    "df0[df0[\"InvoiceNo\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of rows after conditioning\n",
    "print(\"Number of credit transcation, \", df1[df1[\"InvoiceNo\"].str.contains(\"C\")].shape[0])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
